#!/usr/bin/env python3
"""
ä¿®å¤ llama å‘½ä»¤å†²çªé—®é¢˜
"""

import subprocess
import sys
import os
from pathlib import Path

def fix_llama_command():
    """ä¿®å¤ llama å‘½ä»¤å†²çªé—®é¢˜"""
    
    print("ğŸ”§ ä¿®å¤ llama å‘½ä»¤å†²çªé—®é¢˜...")
    print("=" * 50)
    
    # 1. æ£€æŸ¥ llama-stack çš„æ­£ç¡®å‘½ä»¤
    print("\n1. æŸ¥æ‰¾ llama-stack çš„æ­£ç¡®å‘½ä»¤:")
    
    # å°è¯•ä¸åŒçš„å¯èƒ½å‘½ä»¤åç§°
    possible_commands = [
        'llama-stack',
        'llamastack', 
        'llama_stack',
        'python -m llama_stack',
        'python -m llama_stack.cli'
    ]
    
    working_command = None
    
    for cmd in possible_commands:
        try:
            print(f"   æµ‹è¯•å‘½ä»¤: {cmd}")
            if cmd.startswith('python'):
                result = subprocess.run(cmd.split(), capture_output=True, text=True, timeout=5)
            else:
                result = subprocess.run([cmd, '--help'], capture_output=True, text=True, timeout=5)
            
            if result.returncode == 0 and ('llama' in result.stdout.lower() or 'model' in result.stdout.lower()):
                working_command = cmd
                print(f"   âœ… æ‰¾åˆ°å·¥ä½œå‘½ä»¤: {cmd}")
                break
            else:
                print(f"   âŒ å‘½ä»¤ä¸å·¥ä½œ")
                
        except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.CalledProcessError) as e:
            print(f"   âŒ å‘½ä»¤å¤±è´¥: {e}")
    
    if not working_command:
        print("\n2. å°è¯•ç›´æ¥ä½¿ç”¨ Python æ¨¡å—:")
        try:
            # å°è¯•å¯¼å…¥ llama_stack æ¨¡å—
            result = subprocess.run([sys.executable, '-c', 'import llama_stack; print("æ¨¡å—å¯¼å…¥æˆåŠŸ")'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                print("   âœ… llama_stack æ¨¡å—å¯ä»¥å¯¼å…¥")
                
                # å°è¯•æŸ¥æ‰¾æ¨¡å—çš„å‘½ä»¤è¡Œæ¥å£
                result = subprocess.run([sys.executable, '-c', 
                    'import llama_stack; import pkgutil; print([name for _, name, _ in pkgutil.iter_modules(llama_stack.__path__)])'], 
                    capture_output=True, text=True)
                print(f"   æ¨¡å—å†…å®¹: {result.stdout.strip()}")
                
            else:
                print(f"   âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {result.stderr}")
                
        except Exception as e:
            print(f"   âŒ æ£€æŸ¥å¤±è´¥: {e}")
    
    # 3. åˆ›å»ºè§£å†³æ–¹æ¡ˆ
    print(f"\n3. åˆ›å»ºè§£å†³æ–¹æ¡ˆ:")
    
    if working_command:
        print(f"   ä½¿ç”¨å·¥ä½œå‘½ä»¤: {working_command}")
        create_wrapper_script(working_command)
    else:
        print("   æœªæ‰¾åˆ°å·¥ä½œçš„ llama-stack å‘½ä»¤")
        print("   å»ºè®®ä½¿ç”¨æœ€å°åŒ–æ¨¡å‹è®¾ç½®æ–¹æ¡ˆ")
        
    # 4. æä¾›æ›¿ä»£æ–¹æ¡ˆ
    print(f"\n4. æ›¿ä»£æ–¹æ¡ˆ - æœ€å°åŒ–æ¨¡å‹è®¾ç½®:")
    print("   ç”±äº llama å‘½ä»¤å†²çªï¼Œæˆ‘ä»¬å¯ä»¥:")
    print("   a) ä½¿ç”¨ setup_minimal_model.py åˆ›å»ºæµ‹è¯•ç”¨çš„æ¨¡å‹ç»“æ„")
    print("   b) ç»•è¿‡å¤æ‚çš„æ¨¡å‹ä¸‹è½½è¿‡ç¨‹")
    print("   c) ç›´æ¥æµ‹è¯• LLark çš„æ¨¡å‹åŠ è½½åŠŸèƒ½")
    
    print("\n" + "=" * 50)
    print("ğŸ¯ ä¿®å¤åˆ†æå®Œæˆ!")

def create_wrapper_script(working_command):
    """åˆ›å»ºåŒ…è£…è„šæœ¬æ¥ä½¿ç”¨æ­£ç¡®çš„ llama å‘½ä»¤"""
    
    wrapper_path = Path("/home/evev/diversity-eval/external/llark/llama_stack_wrapper.py")
    
    wrapper_content = f'''#!/usr/bin/env python3
"""
LLama Stack åŒ…è£…è„šæœ¬
ç»•è¿‡ç³»ç»Ÿä¸­å†²çªçš„ llama å‘½ä»¤
"""

import subprocess
import sys

def main():
    """è¿è¡Œæ­£ç¡®çš„ llama-stack å‘½ä»¤"""
    
    # ä½¿ç”¨å·¥ä½œçš„å‘½ä»¤
    cmd = "{working_command}"
    
    # ä¼ é€’æ‰€æœ‰å‚æ•°
    if len(sys.argv) > 1:
        if cmd.startswith('python'):
            full_cmd = cmd.split() + sys.argv[1:]
        else:
            full_cmd = [cmd] + sys.argv[1:]
    else:
        if cmd.startswith('python'):
            full_cmd = cmd.split() + ['--help']
        else:
            full_cmd = [cmd, '--help']
    
    try:
        result = subprocess.run(full_cmd)
        sys.exit(result.returncode)
    except Exception as e:
        print(f"é”™è¯¯: {{e}}")
        sys.exit(1)

if __name__ == "__main__":
    main()
'''
    
    with open(wrapper_path, 'w') as f:
        f.write(wrapper_content)
    
    # æ·»åŠ æ‰§è¡Œæƒé™
    wrapper_path.chmod(0o755)
    
    print(f"   âœ… åˆ›å»ºåŒ…è£…è„šæœ¬: {wrapper_path}")
    print(f"   ä½¿ç”¨æ–¹æ³•: python {wrapper_path} model list")

if __name__ == "__main__":
    fix_llama_command()